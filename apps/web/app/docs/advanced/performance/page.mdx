export const metadata = {
  title: 'Performance Tuning',
  description: 'Optimize Vestig for low latency and high throughput in production environments.',
}

# Performance Tuning

Vestig is designed for minimal overhead. This guide covers tuning strategies for different workloads.

## Understanding Overhead

### Logging Path

```
log.info("message")
  ↓
1. Level check (< 1μs)
2. Format args (1-5μs)
3. Build entry (2-5μs)
4. Sanitize (0-10μs)
5. Transport.log() (varies)
```

The hot path (steps 1-4) adds ~10-20μs per log. Transport overhead varies by type.

### Transport Latency

| Transport | Latency per log | Notes |
|-----------|----------------|-------|
| ConsoleTransport | 5-50μs | Fastest, no batching |
| BatchTransport | 1-5μs | Async queue, batch flush |
| HTTPTransport | 1-5μs (buffered) | Network on flush |
| FileTransport | 2-10μs (buffered) | Disk on flush |

## Log Level Optimization

### Production Levels

```typescript
import { createLogger } from 'vestig'

// Development: trace for debugging
const devLogger = createLogger({ level: 'trace' })

// Production: info or above
const prodLogger = createLogger({
  level: process.env.NODE_ENV === 'production' ? 'info' : 'debug'
})
```

### Level Check Short-Circuit

Level checks happen first, before any string formatting:

```typescript
// This is fast when level is 'info' or above
logger.debug('Expensive calculation result:', expensiveFunction())

// The function is STILL called! Use guards for expensive operations:
if (logger.getLevel() === 'debug' || logger.getLevel() === 'trace') {
  logger.debug('Result:', expensiveFunction())
}
```

### Dynamic Level Control

```typescript
import { createLogger } from 'vestig'

const logger = createLogger({ level: 'info' })

// Temporarily enable debug for troubleshooting
function enableDebug(durationMs = 60000) {
  const original = logger.getLevel()
  logger.setLevel('debug')

  setTimeout(() => {
    logger.setLevel(original)
    logger.info('Debug logging disabled')
  }, durationMs)
}

// Expose via API or signal
process.on('SIGUSR1', () => enableDebug(60000))
```

## Sampling Strategies

### Probability Sampling

Reduce log volume while maintaining visibility:

```typescript
import { createLogger } from 'vestig'

const logger = createLogger({
  sampling: {
    enabled: true,
    sampler: 0.1, // Log 10% of entries
  }
})

// 10 logs → 1 stored (statistically)
for (let i = 0; i < 100; i++) {
  logger.info(`Request ${i}`)  // ~10 will be logged
}
```

### Rate Limiting

Prevent log storms:

```typescript
const logger = createLogger({
  sampling: {
    enabled: true,
    sampler: { maxPerSecond: 100 }
  }
})

// Even under 10k req/sec, max 100 logs/sec
```

### Namespace-Based Sampling

Different rates for different subsystems:

```typescript
const logger = createLogger({
  sampling: {
    enabled: true,
    sampler: {
      default: 0.1,  // 10% default
      namespaces: {
        'auth.*': 1.0,        // 100% for auth (security)
        'db.*': 0.01,         // 1% for noisy DB logs
        'http.*': { maxPerSecond: 50 }
      }
    }
  }
})

const authLogger = logger.child('auth')    // 100%
const dbLogger = logger.child('db')        // 1%
const httpLogger = logger.child('http')    // Rate limited
```

## Batching Configuration

### Optimal Batch Size

```typescript
import { HTTPTransport } from 'vestig'

// Low volume: smaller batches, faster feedback
new HTTPTransport({
  batchSize: 25,
  flushInterval: 1000,  // 1 second
})

// High volume: larger batches, fewer requests
new HTTPTransport({
  batchSize: 500,
  flushInterval: 5000,  // 5 seconds
})
```

### Batch Size Formula

```typescript
// Target: < 1MB per batch, < 100 requests/minute

const avgLogSize = 500  // bytes
const logsPerSecond = 1000
const flushInterval = 5  // seconds

const batchSize = logsPerSecond * flushInterval
// 1000 * 5 = 5000 logs per batch
// 5000 * 500 = 2.5MB - TOO BIG!

// Adjust down
const optimalBatchSize = Math.min(
  1000,  // Max batch size
  Math.floor(1_000_000 / avgLogSize)  // ~2000 to stay under 1MB
)
```

### Flush Interval Tuning

```typescript
// Real-time visibility (development)
new HTTPTransport({
  flushInterval: 500,   // 500ms
  batchSize: 50,
})

// Balanced (staging)
new HTTPTransport({
  flushInterval: 2000,  // 2s
  batchSize: 200,
})

// High efficiency (production)
new HTTPTransport({
  flushInterval: 10000, // 10s
  batchSize: 1000,
})
```

## Structured vs Formatted Output

### Structured JSON (Production)

```typescript
const logger = createLogger({
  structured: true,  // Default in production
})

logger.info('Request handled', { duration: 45 })
// {"level":"info","message":"Request handled","metadata":{"duration":45},...}
```

**Pros:**
- Faster parsing by log aggregators
- Consistent format
- No ANSI escape codes

### Formatted Output (Development)

```typescript
const logger = createLogger({
  structured: false,
})

logger.info('Request handled', { duration: 45 })
// [INFO] Request handled { duration: 45 }
```

**Pros:**
- Human readable
- Colored output
- Better for debugging

### Auto-Detection

```typescript
const logger = createLogger({
  structured: process.env.NODE_ENV === 'production'
})
```

## Sanitization Performance

### Field Matching Speed

```typescript
import { createLogger } from 'vestig'

// Fast: Exact field names
const logger = createLogger({
  sanitize: {
    fields: ['password', 'token', 'secret']
  }
})

// Slower: Regex patterns
const slowLogger = createLogger({
  sanitize: {
    fields: [
      { type: 'regex', value: '.*password.*', caseSensitive: false }
    ]
  }
})
```

### Preset Performance

Presets are optimized for common use cases:

```typescript
// Minimal overhead
createLogger({ sanitize: 'minimal' })

// Standard protection
createLogger({ sanitize: 'default' })

// Comprehensive (slight overhead)
createLogger({ sanitize: 'gdpr' })
createLogger({ sanitize: 'pci-dss' })
```

### Disable When Not Needed

```typescript
// Internal service with no sensitive data
const internalLogger = createLogger({
  sanitize: false  // Skip sanitization entirely
})
```

## Transport Selection

### ConsoleTransport

Best for: Development, debugging, low-volume production

```typescript
import { ConsoleTransport } from 'vestig'

new ConsoleTransport({
  structured: false,  // Pretty print
  colors: true,       // ANSI colors
})
```

### HTTPTransport

Best for: Cloud log aggregation (Datadog, Splunk, etc.)

```typescript
import { HTTPTransport } from 'vestig'

new HTTPTransport({
  url: 'https://logs.example.com',
  batchSize: 500,
  flushInterval: 5000,
  timeout: 10000,
  maxRetries: 3,
})
```

### FileTransport

Best for: Local persistence, compliance requirements

```typescript
import { FileTransport } from 'vestig'

new FileTransport({
  path: './logs/app.log',
  batchSize: 100,
  maxSize: 100 * 1024 * 1024,  // 100MB
  maxFiles: 10,
  rotateInterval: 'daily',
  compress: true,  // Gzip rotated files
})
```

### Multiple Transports

Combine for redundancy with minimal overhead:

```typescript
const logger = createLogger()

// Fast local buffer
logger.addTransport(new ConsoleTransport())

// Async remote storage
logger.addTransport(new HTTPTransport({ url: '...' }))

// Logs go to both, batched separately
```

## Async Initialization

### Defer Transport Init

```typescript
import { createLogger, createLoggerAsync, HTTPTransport } from 'vestig'

// Immediate startup (console only)
const logger = createLogger()

// Background: add expensive transports
;(async () => {
  const http = new HTTPTransport({ url: '...' })
  await http.init?.()
  logger.addTransport(http)
})()

// Logs work immediately, HTTP added when ready
logger.info('Server starting')
```

### Parallel Initialization

```typescript
import { createLogger, HTTPTransport, FileTransport, initLogger } from 'vestig'

const logger = createLogger()

// Add all transports
logger.addTransport(new HTTPTransport({ url: '...' }))
logger.addTransport(new FileTransport({ path: './logs/app.log' }))

// Initialize all in parallel
await initLogger(logger)

// Now fully operational
logger.info('All transports ready')
```

## Measuring Performance

### Logging Overhead

```typescript
import { createLogger } from 'vestig'

const logger = createLogger({ level: 'info' })

// Warm up
for (let i = 0; i < 1000; i++) {
  logger.info('warmup')
}
await logger.flush()

// Measure
const iterations = 10000
const start = performance.now()

for (let i = 0; i < iterations; i++) {
  logger.info('Test message', { iteration: i })
}

await logger.flush()
const end = performance.now()

const totalMs = end - start
const perLogUs = (totalMs / iterations) * 1000

console.log(`${perLogUs.toFixed(2)}μs per log`)
console.log(`${iterations / (totalMs / 1000)} logs/second`)
```

### Transport Benchmarks

```typescript
import { ConsoleTransport, HTTPTransport, FileTransport } from 'vestig'

async function benchmarkTransport(transport: Transport, name: string) {
  const iterations = 1000

  const start = performance.now()
  for (let i = 0; i < iterations; i++) {
    transport.log({ level: 'info', message: 'test', timestamp: new Date().toISOString() })
  }
  await transport.flush?.()
  const end = performance.now()

  console.log(`${name}: ${((end - start) / iterations * 1000).toFixed(2)}μs per log`)
}

await benchmarkTransport(new ConsoleTransport(), 'Console')
await benchmarkTransport(new HTTPTransport({ url: '...' }), 'HTTP')
await benchmarkTransport(new FileTransport({ path: '/tmp/bench.log' }), 'File')
```

## Production Checklist

### Configuration

```typescript
const prodLogger = createLogger({
  // Performance
  level: 'info',           // No debug/trace
  structured: true,        // Fast JSON
  sanitize: 'default',     // Standard protection

  // Sampling
  sampling: {
    enabled: true,
    sampler: {
      default: 0.1,        // 10% sampling
      namespaces: {
        'error.*': 1.0,    // 100% errors
      }
    }
  }
})

// Transport tuning
prodLogger.addTransport(new HTTPTransport({
  url: process.env.LOG_ENDPOINT,
  batchSize: 500,
  flushInterval: 5000,
  timeout: 10000,
  maxRetries: 3,
}))
```

### Monitoring

```typescript
import { createMetricsCollector } from 'vestig'

const metrics = createMetricsCollector()

// Export to Prometheus
app.get('/metrics', (req, res) => {
  res.type('text/plain')
  res.send(metrics.toPrometheus())
})
```

### Quick Wins

| Optimization | Impact | Effort |
|-------------|--------|--------|
| Set level to 'info' | High | Low |
| Enable sampling | High | Low |
| Increase batch size | Medium | Low |
| Use structured format | Medium | Low |
| Disable sanitize (if safe) | Low | Low |
| Async transport init | Low | Medium |
